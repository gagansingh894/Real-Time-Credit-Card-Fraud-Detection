# Base image: Airflow 2.7.3
FROM apache/airflow:2.7.3-python3.11

# Switch to root to install packages
USER root

# Install Java (OpenJDK 11) and wget/unzip
RUN apt-get update && \
    apt-get install -y openjdk-11-jdk wget curl unzip git && \
    apt-get clean && rm -rf /var/lib/apt/lists/*

# Set JAVA_HOME
ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
ENV PATH=$JAVA_HOME/bin:$PATH

# Set Airflow home
ENV AIRFLOW_HOME=/opt/airflow

# Copy DAGs into the container
COPY ../dags/ ${AIRFLOW_HOME}/dags/

# Copy Spark Jobs into container
COPY ../spark_jobs/ ${AIRFLOW_HOME}/spark_jobs/

# Switch back to airflow user
USER airflow

# Install Python dependencies
RUN pip install --no-cache-dir \
    "apache-airflow==2.7.3" \
    "apache-airflow-providers-apache-spark>=4.9.0" \
    "cassandra-driver<=3.29" \
    "confluent-kafka==2.10" \
    "flask-session>=0.5.0" \
    "mlflow==3.2" \
    "numpy==2.2" \
    "pydantic==2.10" \
    "pyspark<=3.5.6"

