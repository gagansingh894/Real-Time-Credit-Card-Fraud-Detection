services:
  cassandra1:
    image: cassandra:4.1
    container_name: cassandra1
    environment:
      - CASSANDRA_CLUSTER_NAME=fraud-cluster
      - CASSANDRA_DC=dc1
      - CASSANDRA_RACK=rack1
      - CASSANDRA_ENDPOINT_SNITCH=GossipingPropertyFileSnitch
      - CASSANDRA_NUM_TOKENS=256
      - MAX_HEAP_SIZE=512M   # JVM heap max
      - HEAP_NEWSIZE=256M    # JVM young generation
    deploy:
      resources:
        limits:
          memory: 1g          # limit container memory to 1GB
    ports:
      - "9042:9042"   # CQL
      - "9160:9160"   # Thrift (optional, legacy)
  cassandra2:
    image: cassandra:4.1
    container_name: cassandra2
    environment:
      - CASSANDRA_CLUSTER_NAME=fraud-cluster
      - CASSANDRA_DC=dc1
      - CASSANDRA_RACK=rack1
      - CASSANDRA_ENDPOINT_SNITCH=GossipingPropertyFileSnitch
      - CASSANDRA_NUM_TOKENS=256
      - MAX_HEAP_SIZE=512M   # JVM heap max
      - HEAP_NEWSIZE=256M    # JVM young generation
    deploy:
      resources:
        limits:
          memory: 1g          # limit container memory to 1GB
    ports:
      - "9043:9042"   # CQL
      - "9161:9160"   # Thrift (optional, legacy)
  cassandra-init:
    image: cassandra:4.1
    depends_on:
      - cassandra1
      - cassandra2
    entrypoint: >
      bash -c "
        echo 'Waiting for Cassandra nodes...';
        until cqlsh cassandra1 9042 -e 'describe cluster'; do
          echo 'Waiting for cassandra1...';
          sleep 5;
        done;
        until cqlsh cassandra2 9042 -e 'describe cluster'; do
          echo 'Waiting for cassandra2...';
          sleep 5;
        done;
        echo 'Nodes are ready. Running CQL scripts...';
        cqlsh cassandra1 9042 -f /creditcard.cql
      "
    volumes:
      - ./creditcard.cql:/creditcard.cql
  spark-master:
    image: bitnami/spark:3.5
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
    ports:
      - "7077:7077"
      - "8080:8080"
  spark-worker-1:
    image: bitnami/spark:3.5
    container_name: spark-worker-1
    ports:
      - "8081:8081"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
    depends_on:
      - spark-master
  spark-worker-2:
    image: bitnami/spark:3.5
    container_name: spark-worker-2
    ports:
      - "8082:8081"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
    depends_on:
      - spark-master
  minio:
    image: minio/minio:latest
    container_name: minio
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9009"
    ports:
      - "9000:9000"
      - "9009:9009"
    volumes:
      - ./minio-data:/data
  minio-init:
    image: minio/mc
    depends_on:
      - minio
    entrypoint: >
      bash -c "
        echo 'Waiting for MinIO...';
        until (mc alias set myminio http://minio:9000 minioadmin minioadmin); do
          echo 'Waiting for MinIO to start...';
          sleep 5;
        done;
        echo 'Creating bucket mlflow...';
        mc mb -p myminio/mlflow || echo 'Bucket already exists';
        mc ls myminio
      "
  postgres:
    image: postgres:15
    container_name: postgres
    environment:
      POSTGRES_USER: mlflow
      POSTGRES_PASSWORD: mlflow123
      POSTGRES_DB: mlflow_db
    ports:
      - "5432:5432"
    volumes:
      - ./postgres-data:/var/lib/postgresql/data
  mlflow:
    image: python:3.11
    container_name: mlflow
    depends_on:
      - minio
      - postgres
    environment:
      BACKEND_STORE_URI: postgresql+psycopg2://mlflow:mlflow@postgres:5432/mlflow
      ARTIFACT_ROOT: s3://mlflow/
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      MLFLOW_HOST: 0.0.0.0
      MLFLOW_PORT: 5005
    command: >
      bash -c "
        pip install mlflow[extras] psycopg2-binary &&
        mlflow server \
          --backend-store-uri postgresql+psycopg2://mlflow:mlflow123@postgres:5432/mlflow_db \
          --default-artifact-root s3://mlflow/ \
      "
    ports:
      - "5005:5005"
    volumes:
      - ./mlflow:/mlflow